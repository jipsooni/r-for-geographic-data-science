---
title: "Lecture 321"
author: "granolarr by Dr Stefano De Sabbata<br/>School of Geography, Geology, and the Env.<br/>University of Leicester<br/><a href=\"https://github.com/sdesabbata/granolarr\">github.com/sdesabbata/granolarr</a><br/><a href=\"mailto:s.desabbata@le.ac.uk\">s.desabbata&commat;le.ac.uk</a> &vert; <a href=\"https://twitter.com/maps4thought\">&commat;maps4thought</a><br/>licensed under <a href=\"https://www.gnu.org/licenses/gpl-3.0.html\">GNU GPL v3.0</a>"
date: "`r Sys.Date()`"
output:
  ioslides_presentation:
    template: ../utils/IOSlides/UoL_Template.html
    logo: ../../src/utils/IOSlides/uol_logo.png
    css: ../utils/RMarkdown/rmarkdown_classes.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_knit$set(root.dir = Sys.getenv("RGDS_HOME"))
rm(list = ls())
```

<style type="text/css">
.small_r_all pre{
  font-size: 16px !important;
  line-height: 18px !important;
}
.small_r_output pre:not(.prettyprint){
  font-size: 16px;
  line-height: 18px;
}
.verysmall_r_output pre:not(.prettyprint){
  font-size: 12px;
  line-height: 14px;
}
</style>



# Simple Regression


## Recap

**Prev**: Comparing data

- 311 Lecture Comparing groups
- 312 Lecture Correlation
- 313 Lecture Data transformations
- 314 Practical session

**Now**: Simple Regression

- Regression
- Ordinary Least Squares
- Interpretation
- Checking assumptions



```{r, echo=FALSE, message=FALSE, warning=FALSE,}
library(tidyverse)
library(magrittr)  
library(palmerpenguins)
library(lmtest)
```


## Regression analysis

**Regression analysis** is a supervised machine learning approach

Special case of the general linear model

$$outcome_i = (model) + error_i $$

Predict (estimate) value of one outcome (dependent) variable as

- one predictor (independent) variable: **simple / univariate**

$$Y_i = (b_0 + b_1 * X_{i1}) + \epsilon_i $$
    
- more predictor (independent) variables: **multiple / multivar.**

$$Y_i = (b_0 + b_1 * X_{i1} + b_2 * X_{i2} + \dots + b_M * X_{iM}) + \epsilon_i $$

## Example

Can we predict a penguin's body mass from flipper length?

$$body\ mass_i = (b_0 + b_1 * flipper\ length_{i}) + \epsilon_i $$

<center>
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width = 6, fig.height = 4}
palmerpenguins::penguins %>%
  ggplot2::ggplot(aes(x = flipper_length_mm, y = body_mass_g)) +
  ggplot2::geom_point(aes(color = species,
                 shape = species),
             size = 2) +
  ggplot2::scale_color_manual(values = c("darkorange","darkorchid","cyan4")) +
  ggplot2::theme_bw()
```
</center>


## Example

Can we predict a penguin's body mass from flipper length?

$$body\ mass_i = (b_0 + b_1 * flipper\ length_{i}) + \epsilon_i $$

<center>
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width = 6, fig.height = 4}
palmerpenguins::penguins %>%
  ggplot2::ggplot(aes(x = flipper_length_mm, y = body_mass_g)) +
  ggplot2::geom_point(aes(color = species,
                 shape = species),
             size = 2) +
  ggplot2::scale_color_manual(values = c("darkorange","darkorchid","cyan4")) +
  geom_smooth(method=lm) +
  ggplot2::theme_bw()
```
</center>



## Least squares

:::::: {.cols data-latex=""}

::: {.col data-latex="{0.5\textwidth}"}

**Least squares** is the most commonly used approach to generate a regression model

The model fits a line
    
- to **minimise** the squared values of the **residuals** (errors)
- that is squared difference between
    - **observed values**
    - **model**

:::

::: {.col data-latex="{0.5\textwidth}"}

<center>
![](images/489px-Linear_least_squares_example2.svg.png){width=70%}

<br/>
<font size="4"> 
by  Krishnavedala<br/>
via Wikimedia Commons,<br/>CC-BY-SA-3.0
</font>
</center>

:::
::::::

$$residual_i = observed_i - model_i$$
$$deviation = \sum_i(observed_i - model_i)^2$$


## Assumptions

- **Linearity**
    - the relationship is actually linear
- **Normality** of residuals
    - standard residuals are normally distributed with mean `0`
- **Homoscedasticity** of residuals
    - at each level of the predictor variable(s) the variance of the standard residuals should be the same (*homo-scedasticity*) rather than different (*hetero-scedasticity*) 
- **Independence** of residuals
    - adjacent standard residuals are not correlated


## stats::lm

<div class="small_r_all">

```{r, echo=TRUE}
bm_fl_model <-
  palmerpenguins::penguins %>%
  dplyr::filter(!is.na(body_mass_g) | !is.na(flipper_length_mm)) %$%
  stats::lm(body_mass_g ~ flipper_length_mm)

bm_fl_model %>%  
  summary()
```

</div>



## Overall fit

```{r, echo=FALSE}
bm_fl_model_summary <- bm_fl_model %>%
  summary()
```

The output indicates

- **p-value: < 2.2e-16**: $p<.01$ the model is significant
  - derived by comparing **F-statistic** (`r bm_fl_model_summary$fstatistic[1] %>% round(digits = 2)`) to F distribution having specified degrees of freedom (`r bm_fl_model_summary$fstatistic[2]`, `r bm_fl_model_summary$fstatistic[3]`)
  - Report as: F(`r bm_fl_model_summary$fstatistic[2]`, `r bm_fl_model_summary$fstatistic[3]`) = `r bm_fl_model_summary$fstatistic[1] %>% round(digits = 2)`
- **Adjusted R-squared: `r bm_fl_model_summary$adj.r.squared %>% round(digits = 4)`**: 
  - flipper length can account for `r (bm_fl_model_summary$adj.r.squared * 100) %>% round(digits = 2)`% variation in body mass
- **Coefficients**
  - Intercept estimate `r bm_fl_model_summary$coefficients[1,1] %>% round(digits = 4)` is significant
  - `flipper_length_mm` (slope) estimate `r bm_fl_model_summary$coefficients[2,1] %>% round(digits = 4)` is significant



## Outliers and influential cases

<div class="small_r_all">

```{r, echo=TRUE, message=FALSE, warning=FALSE}
penguins_output <-
  palmerpenguins::penguins %>%
  dplyr::filter(!is.na(body_mass_g) | !is.na(flipper_length_mm)) %>%
  mutate(
    model_stdres = bm_fl_model %>% stats::rstandard(),
    model_cook_dist = bm_fl_model %>% stats::cooks.distance()
  )

penguins_output %>%
  dplyr::select(body_mass_g, model_stdres, model_cook_dist) %>%
  dplyr::filter(abs(model_stdres) > 2.58 | model_cook_dist > 1)
```

</div>

No influential cases (Cook's distance `> 1`) but there are a handful of outliers (4 abs std res `> 2.58`)


## Checking assumptions: normality

Shapiro-Wilk test for normality of standard residuals, 

- robust models: should be **not** significant 

:::::: {.cols data-latex=""}

::: {.col data-latex="{0.5\textwidth}"}

```{r, echo=TRUE, message=FALSE, warning=FALSE}
penguins_output %$% 
  stats::shapiro.test(
    model_stdres
  )
```

<font size="4"> 
**Standard residuals are normally distributed!**
</font>

:::

::: {.col data-latex="{0.5\textwidth}"}

<center>
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width = 3, fig.height = 3}
penguins_output %>%
  ggplot2::ggplot(aes(x = model_stdres)) +
  ggplot2::geom_histogram(
    aes(
      y =..density..
    ),
    bins = 100
  ) + 
  ggplot2::stat_function(
    fun = dnorm, 
    args = list(
      mean = penguins_output %>% pull(model_stdres) %>% mean(),
      sd = penguins_output %>% pull(model_stdres) %>% sd()),
    colour = "red", size = 1)
```
</center>

:::
::::::

</div>



## Checking assumpt.: homoscedasticity

Breusch-Pagan test for homoscedasticity of standard residuals

- robust models: should be **not** significant

<div class="small_r_output">

:::::: {.cols data-latex=""}

::: {.col data-latex="{0.5\textwidth}"}

```{r, echo=TRUE, message=FALSE, warning=FALSE, fig.width = 3, fig.height = 3}
bm_fl_model %>% 
  lmtest::bptest()
```

<font size="4"> 
**Standard residuals are homoscedastic!**
</font>

:::

::: {.col data-latex="{0.5\textwidth}"}

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width = 3, fig.height = 3}
bm_fl_model %>% 
  plot(which = c(1))
```

:::
::::::

</div>



## Checking assumptions: independence

Durbin-Watson test for the independence of residuals

- robust models: statistic should be close to 2 (advised between 1 and 3) and **not** significant

<div class="small_r_output">

```{r, echo=TRUE}
bm_fl_model %>%
  lmtest::dwtest()
```

</div>

<font size="4"> 
**Standard residuals are independent!**

Note: the result depends on the order of the data.
</font>



## Example

Yes, we can predict a penguin's body mass from flipper length!

$$body\ mass_i = (-5780.83 + 49.69 * flipper\ length_{i}) + \epsilon_i $$

<center>
```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width = 6, fig.height = 4}
palmerpenguins::penguins %>%
  ggplot2::ggplot(aes(x = flipper_length_mm, y = body_mass_g)) +
  ggplot2::geom_point(aes(color = species,
                 shape = species),
             size = 2) +
  ggplot2::scale_color_manual(values = c("darkorange","darkorchid","cyan4")) +
  geom_smooth(method=lm) +
  ggplot2::theme_bw()
```
</center>


## Summary

Simple Regression

- Regression
- Ordinary Least Squares
- Interpretation
- Checking assumptions

**Next**: Multiple Regression

- Multiple regression
- Interpretation
- Checking assumptions

```{r cleanup, include=FALSE}
rm(list = ls())
```
